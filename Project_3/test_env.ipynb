{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _collections import defaultdict\n",
    "from functools import reduce\n",
    "import re\n",
    "import math\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_TAG = '<UNK>'\n",
    "DIGIT_TAG = '<NUM>'\n",
    "WEB_TAG = '<WEB>'\n",
    "LANDAS =[0.15966386554621848, 0.008403361344537815, 0.8319327731092437]\n",
    "MOST_COMMON = {\n",
    "    \"the\", \"be\", \"to\", \"of\", \"and\", \"a\", \"that\", \"have\", \"i\"\n",
    "                , \"it\", \"for\", \"not\", \"on\", \"he\", \"as\", \"you\", \"do\", \"at\", \"this\", \"but\"\n",
    "                , \"his\", \"by\", \"from\", \"they\", \"we\", \"her\", \"she\", \"or\", \"an\", \"will\", \"my\", \"would\"\n",
    "                , \"all\", \"me\", \"when\", \"no\", \"just\", \"him\",\"e\" \"<num>\" , \"d\", \n",
    "    UNK_TAG , DIGIT_TAG , WEB_TAG, \".\",\"<num>\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(path):\n",
    "    with open(path, '+r') as file:\n",
    "        lines = format_data(file.readlines())\n",
    "        return lines\n",
    "\n",
    "\n",
    "def find_unk(lines):\n",
    "    curpus = ' ////// '.join(lines)\n",
    "    words = set(curpus.split())\n",
    "    for word in words:\n",
    "        if curpus.count(word) == 1:\n",
    "            curpus = curpus.replace(word, UNK_TAG)\n",
    "    lines = curpus.split(' ////// ')\n",
    "    # print(lines)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(lines):\n",
    "    formatted_lines = list(map(\n",
    "        lambda x: re.sub('https?\\s*:\\s*/\\s*/\\s*[^\\s<>\"]+|www\\.[^\\s<>\"]', WEB_TAG,\n",
    "                         x), lines))\n",
    "    formatted_lines = list(map(lambda x: re.sub(\"[^a-zA-Z.0-9$]\", ' ', x), formatted_lines))\n",
    "    # formatted_lines = list(map(lambda x: re.sub(\"\\s'\", \"'\", x), formatted_lines))\n",
    "    formatted_lines = list(map(lambda x: re.sub('\\d{1,}', f' {DIGIT_TAG} ', x), formatted_lines))\n",
    "    formatted_lines = [' '.join(line.strip().lower().split()) for line in formatted_lines]\n",
    "    formatted_lines = ['<s> ' * 2 + line + ' <s/>' for line in formatted_lines]\n",
    "    return formatted_lines\n",
    "\n",
    "\n",
    "def generate_n_gram(n, lines):\n",
    "    grams = []\n",
    "    for sentence in lines:\n",
    "        words = sentence.split()\n",
    "        for i in range(len(words) - n):\n",
    "            gram = words[i:i + n]\n",
    "            if gram not in grams:\n",
    "                grams.append(gram)\n",
    "    return grams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(lines):\n",
    "    unigrams = defaultdict(lambda: 0)\n",
    "    bigrams = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    trigrams = defaultdict(lambda: defaultdict(lambda: 0))\n",
    "    text = ' '.join(lines)\n",
    "    s = len(text)\n",
    "    # print('wrongly' in text)\n",
    "    p_unigrams = defaultdict(lambda: 1 / s)\n",
    "    p_bigrams = defaultdict(lambda: defaultdict(lambda: 1 / s))\n",
    "    p_trigrams = defaultdict(lambda: defaultdict(lambda: 1 / s))\n",
    "    words = set()\n",
    "    for k in generate_n_gram(1, lines):\n",
    "        unigrams[k[0]] += text.count(k[0])\n",
    "        p_unigrams[k[0]] = unigrams[k[0]] / s\n",
    "        words.add(k[0])\n",
    "        assert (p_unigrams[k[0]] <= 1)\n",
    "        # if unigrams[k[0]] == 1:\n",
    "        #     unigrams[UNK_TAG] += 1\\\n",
    "    print('unigrams computed')\n",
    "    for k in generate_n_gram(2, lines):\n",
    "        k.__contains__('panic')\n",
    "        tmp = ' '.join(k)\n",
    "        bigrams[k[0]][k[1]] += text.count(tmp)\n",
    "        p_bigrams[k[0]][k[1]] = bigrams[k[0]][k[1]] / unigrams[k[0]]\n",
    "        assert (p_bigrams[k[0]][k[1]] <= 1)\n",
    "\n",
    "    print('bigrams computed')\n",
    "    for k in generate_n_gram(3, lines):\n",
    "        tmp = ' '.join(k)\n",
    "        trigrams[(k[0], k[1])][k[2]] += text.count(tmp)\n",
    "        p_trigrams[(k[0], k[1])][k[2]] = trigrams[(k[0], k[1])][k[2]] / bigrams[k[0]][k[1]]\n",
    "        assert (p_trigrams[(k[0], k[1])][k[2]] <= 1)\n",
    "    print('trigrams computed')\n",
    "    return {\n",
    "        'trigram': p_trigrams,\n",
    "        'bigram': p_bigrams,\n",
    "        'unigram': p_unigrams,\n",
    "        'words': words,\n",
    "        'size': s\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_test(pathes):\n",
    "    with open(pathes[0], '+r') as file:\n",
    "        lines = format_data(file.readlines())\n",
    "    with open(pathes[1], '+r') as file:\n",
    "        labels = list(map(lambda x: re.sub('[^a-zA-Z.$]', ' ', x), file.readlines()))\n",
    "        labels = [' '.join(label.strip().lower().split()) for label in labels]\n",
    "    return lines, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(words, model, real, some_random_words, landa):\n",
    "    unigram, bigram, trigram = model['unigram'], model['bigram'], model['trigram']\n",
    "    predicts = set(\n",
    "        list(trigram[(words[0], words[1])].keys()) + list(bigram[words[1]].keys()) + some_random_words).difference(\n",
    "        MOST_COMMON)\n",
    "    max_prob = -1\n",
    "    best_pr = ''\n",
    "#     print(f'predict set has it : {real in predicts}\\n')\n",
    "#     print(f'prediction set : {len(predicts)}\\n')\n",
    "    for pr in predicts:\n",
    "        prob = get_prob(unigram, bigram, trigram, pr, words, landa)\n",
    "#         print(f'{pr} : {prob}')\n",
    "        if prob > max_prob:\n",
    "            max_prob = prob\n",
    "            best_pr = pr\n",
    "\n",
    "    return best_pr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_landas(seed):\n",
    "    random.seed(seed)\n",
    "    arr = [random.randint(1, 100) for _ in range(3)]\n",
    "    s = sum(arr)\n",
    "    arr = list(map(lambda x: x / s, arr))\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_off(unigram, bigram, trigram, words, landa):\n",
    "    return landa[0] * trigram[(words[0], words[1])][words[2]] + landa[1] * bigram[words[1]][words[2]] + landa[2] * \\\n",
    "           unigram[words[2]]\n",
    "\n",
    "\n",
    "def get_prob(unigram, bigram, trigram, pr, words, landa):\n",
    "    tmp = [[words[0], words[1], pr], [words[1], pr, words[2]], [pr, words[2], words[3]]]\n",
    "    prob = reduce(lambda x, y: x * y, [back_off(unigram, bigram, trigram, t, landa) for t in tmp])\n",
    "    return prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_words(unigram, size):\n",
    "    m = min(unigram.values())\n",
    "    random_words = list(filter(lambda x: unigram[x] <= m, unigram.keys()))\n",
    "\n",
    "    def select_random(seed):\n",
    "        random.seed(seed)\n",
    "        words = random.choices(random_words, k=5)\n",
    "        return words\n",
    "\n",
    "    return select_random\n",
    "\n",
    "\n",
    "def cost_function(y_hat, y):\n",
    "    return math.fabs(y_hat ** 2 - y ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(lines, labels, model, landa):\n",
    "    counter = 0\n",
    "    cost = 0\n",
    "    random_selector = get_random_words(model['unigram'], model['size'])\n",
    "    print('testing started')\n",
    "    for i in range(len(lines)):\n",
    "        l = lines[i].split()\n",
    "        j = l.index('$')\n",
    "        words = l[j - 2:j] + l[j + 1:j + 3]\n",
    "        piece = list(filter(lambda x: UNK_TAG if x not in model['words'] else x, words))\n",
    "#         print('--------------------------------\\n')\n",
    "#         print(f'sentence : {i}\\n')\n",
    "#         print(piece)\n",
    "        s = predict(piece, model, labels[i], random_selector(i), landa)\n",
    "        if s == labels[i]:\n",
    "            counter += 1\n",
    "            print(\n",
    "                f\"success : predicted : {s}:{model['unigram'][s]} , real : {labels[i]} :{model['unigram'][labels[i]]}\\n\")\n",
    "        else:\n",
    "            pass\n",
    "#             print(\n",
    "#                 f\"failure : predicted : {s}:{model['unigram'][s]} , real : {labels[i]}: {model['unigram'][labels[i]]}\\n\")\n",
    "#         print(f\"trained data has it: {labels[i] in model['words']}\")\n",
    "        cost += cost_function(get_prob(model['unigram'], model['bigram'], model['trigram'], s, words, landa),\n",
    "                              get_prob(model['unigram'], model['bigram'], model['trigram'], labels[i], words, landa))\n",
    "\n",
    "    print(f'total cost: {cost} count: {counter}')\n",
    "    return counter, cost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_landas(lines_test, labels, model, num_iteration=5):\n",
    "    all_landas = dict()\n",
    "    for i in range(num_iteration):\n",
    "        landa = get_random_landas(i)\n",
    "        count, cost = test(lines_test, labels, model, landa)\n",
    "        try:\n",
    "            if all_landas[count][0] > cost:\n",
    "                all_landas[count] = [cost, landa]\n",
    "        except:\n",
    "            all_landas[count] = [cost, landa]\n",
    "\n",
    "    print(f'min cost : {max(all_landas.keys())}')\n",
    "    return all_landas[max(all_landas.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_train = get_data('Train_data.rtf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigrams computed\n",
      "bigrams computed\n",
      "trigrams computed\n"
     ]
    }
   ],
   "source": [
    "model = learn(lines_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_test, labels = read_test(['Test_data.rtf', 'labels.rtf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing started\n",
      "success : predicted : disease:3.696538807496581e-05 , real : disease :3.696538807496581e-05\n",
      "\n",
      "success : predicted : improved:1.2321796024988602e-05 , real : improved :1.2321796024988602e-05\n",
      "\n",
      "success : predicted : high:0.00019714873639981763 , real : high :0.00019714873639981763\n",
      "\n",
      "success : predicted : decided:1.8482694037482904e-05 , real : decided :1.8482694037482904e-05\n",
      "\n",
      "success : predicted : product:9.241347018741451e-05 , real : product :9.241347018741451e-05\n",
      "\n",
      "success : predicted : about:0.00029572310459972646 , real : about :0.00029572310459972646\n",
      "\n",
      "success : predicted : with:0.0011336052342989513 , real : with :0.0011336052342989513\n",
      "\n",
      "success : predicted : statement:9.857436819990882e-05 , real : statement :9.857436819990882e-05\n",
      "\n",
      "success : predicted : example:1.8482694037482904e-05 , real : example :1.8482694037482904e-05\n",
      "\n",
      "success : predicted : style:4.3126286087460105e-05 , real : style :4.3126286087460105e-05\n",
      "\n",
      "success : predicted : efforts:3.0804490062471504e-05 , real : efforts :3.0804490062471504e-05\n",
      "\n",
      "success : predicted : with:0.0011336052342989513 , real : with :0.0011336052342989513\n",
      "\n",
      "success : predicted : seems:3.0804490062471504e-05 , real : seems :3.0804490062471504e-05\n",
      "\n",
      "success : predicted : about:0.00029572310459972646 , real : about :0.00029572310459972646\n",
      "\n",
      "success : predicted : down:0.00016018334832485184 , real : down :0.00016018334832485184\n",
      "\n",
      "success : predicted : in:0.014527397513461562 , real : in :0.014527397513461562\n",
      "\n",
      "total cost: 3.8332103202273977e-10 count: 16\n",
      "(16, 3.8332103202273977e-10)\n"
     ]
    }
   ],
   "source": [
    "print(test(lines_test, labels, model , LANDAS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'3'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'1' , '2' , '3'}.difference({'1','2'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_cost(words , landas , unigram , bigram , trigram):\n",
    "    return math.log(back_off(unigram , bigram , trigram , words , landas))/3\n",
    "\n",
    "def gradient()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
